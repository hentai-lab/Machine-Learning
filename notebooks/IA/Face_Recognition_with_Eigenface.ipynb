{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Recognition with Eigenface",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii5EBkDZDz4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade face_recognition\n",
        "!pip install --upgrade opencv-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV0LT71MEL3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import face_recognition\n",
        "import cv2\n",
        "import numpy\n",
        "\n",
        "from IPython.display import display, Javascript, Image, clear_output\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "import urllib\n",
        "\n",
        "!wget -O me.jpg 'https://media.licdn.com/dms/image/C4D03AQHDsuwJf6rX0w/profile-displayphoto-shrink_200_200/0?e=1574899200&v=beta&t=Ny70D9QQIWbtkZGngLPn2yPih10tf0W-m6qwHM3NtXQ'\n",
        "!ls -la\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  resp = urllib.request.urlopen(data)\n",
        "  image = numpy.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "  image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        "\n",
        "  return image\n",
        "\n",
        "eu_image = face_recognition.load_image_file(\"me.jpg\")\n",
        "eu_face_encoding = face_recognition.face_encodings(eu_image)[0]\n",
        "\n",
        "known_face_encodings = [\n",
        "    eu_face_encoding,\n",
        "]\n",
        "known_face_names = [\n",
        "    \"Matheus\",\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1--M4ohHpc07",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "face_locations = []\n",
        "face_encodings = []\n",
        "face_names = []\n",
        "process_this_frame = True\n",
        "first = True\n",
        "\n",
        "filename = 'result.jpg'\n",
        "scale = 4\n",
        "\n",
        "while True:\n",
        "    frame = take_photo()\n",
        "    small_frame = cv2.resize(frame, (0, 0), fx=1/scale, fy=1/scale)\n",
        "    rgb_small_frame = small_frame[:, :, ::-1]\n",
        "    \n",
        "    if process_this_frame:\n",
        "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
        "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
        "\n",
        "        face_names = []\n",
        "        for face_encoding in face_encodings:\n",
        "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
        "            name = \"Homossexual\"\n",
        "\n",
        "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
        "            best_match_index = numpy.argmin(face_distances)\n",
        "            if matches[best_match_index]:\n",
        "                name = known_face_names[best_match_index]\n",
        "\n",
        "            face_names.append(name)\n",
        "\n",
        "    process_this_frame = not process_this_frame\n",
        "\n",
        "    for (top, right, bottom, left), name in zip(face_locations, face_names):\n",
        "        top *= scale\n",
        "        right *= scale\n",
        "        bottom *= scale\n",
        "        left *= scale\n",
        "\n",
        "        cv2.rectangle(frame, (left, top), (right, bottom), (100, 0, 100), 2)\n",
        "\n",
        "        cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (100, 0, 100), cv2.FILLED)\n",
        "        font = cv2.FONT_HERSHEY_DUPLEX\n",
        "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1)\n",
        "        \n",
        "    clear_output()\n",
        "    cv2_imshow(frame)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
